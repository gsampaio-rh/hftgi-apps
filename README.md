# Hugging Face Text Inference Apps

**Hugging Face Text Inference Apps** demonstrates the integration of Hugging Face's Large Language Models (LLMs) with Kafka for real-time text processing and inference. This small-scale project showcases how to leverage cutting-edge NLP technologies to analyze, understand, and interact with text data streamed through Kafka messaging systems.

## Components

- **[LangChain](https://github.com/hwchase17/langchain)**: Provides the backbone for generating responses and analyzing texts using Large Language Models.
- **Kafka Integration**: Utilizes KafkaConsumer and KafkaProducer for consuming and producing messages within a Kafka cluster.
- **[HuggingFace LLMs](https://huggingface.co/models)**: Leverages HuggingFace's APIs for text generation and embeddings to enhance response quality and contextual understanding.

## Features

- **Conversation Handling**: Processes incoming chat messages from a Kafka topic, extracting structured information and analyzing sentiment.
- **Information Extraction**: Converts chat messages into structured JSON format, identifying key pieces of information such as names, emails, and issues described within the conversation.
- **Sentiment Analysis**: Analyzes the sentiment of the conversations, categorizing them as positive or negative based on the content.
- **Kafka Communication**: Consumes messages from a designated chat topic and publishes responses to an answer topic, facilitating real-time chat interaction.

## Prerequisites

- Python 3.x
- Kafka cluster setup
- Access to HuggingFace API for embeddings and text generation
- Necessary Python libraries: `langchain`, `kafka-python`, `json`, `logging`, `uuid`

## How the application works

To convert the example conversation into a structured JSON format as shown, the application performs several steps. Below is a brief explanation of each step involved in the process:

1. **Receive Conversation**: The application listens for messages on the Kafka `chat` topic, each message containing a conversation similar to the provided example.

2. **Extract Information**: Upon receiving a message, the application utilizes predefined templates and Natural Language Processing (NLP) techniques to extract key pieces of information from the conversation. This includes names, emails, phone numbers, departments, issues, and any additional relevant details.

3. **Perform Sentiment Analysis**: In addition to extracting structured information, the application performs sentiment analysis on parts of the conversation (like the detailed description of the issue) to determine the overall sentiment as "Positive" or "Negative". This is achieved using sentiment analysis models available through Hugging Face's APIs.

4. **Generate Structured JSON**: The extracted information and sentiment analysis result are then compiled into a structured JSON format. This JSON object includes fields such as `name`, `email`, `phone_number`, `department`, `issue`, `service`, `additional_information`, and a nested object for `sentiment_analysis`.

5. **Publish Results**: Finally, the structured JSON is packaged with a unique `id` and the original `conversation` text, and then published to the Kafka `answer` topic. This allows downstream applications or services to consume and act upon the processed data.

This process showcases the powerful combination of NLP for text analysis and Kafka for real-time messaging, enabling the automated handling and analysis of conversational data.

### Conversation Input

```txt
Entrevistador: Ol√°, como posso ajud√°-lo hoje? Vamos come√ßar com algumas perguntas b√°sicas. Qual √© o seu nome?
Pessoa: Meu nome √© Maria Costa.

Entrevistador: √ìtimo, Maria Costa! Qual √© o seu email?
Pessoa: Meu email √© maria.costa@email.com.

Entrevistador: Perfeito! E qual √© o n√∫mero do seu telefone celular?
Pessoa: Meu n√∫mero de telefone celular √© (31) 77777-6666.

Entrevistador: Agora, precisamos de algumas informa√ß√µes espec√≠ficas sobre a manifesta√ß√£o. Qual √© o √≥rg√£o relacionado com a manifesta√ß√£o?
Pessoa: O √≥rg√£o relacionado √© Departamento de Sa√∫de.

Entrevistador: Entendido. E qual √© o local relacionado √† sua manifesta√ß√£o?
Pessoa: O local √© Rua XV de Novembro, n√∫mero 300, S√£o Paulo.

Entrevistador: Certo. Qual √© o servi√ßo para o qual deve ser lan√ßada a manifesta√ß√£o?
Pessoa: O servi√ßo √© atendimento de sa√∫de.

Entrevistador: √ìtimo. Sobre o que voc√™ gostaria de falar?
Pessoa: Eu gostaria de falar sobre falta de m√©dicos nos postos de sa√∫de da regi√£o central.

Entrevistador: Entendi. Quem s√£o os envolvidos na sua manifesta√ß√£o?
Pessoa: Os envolvidos s√£o pacientes que dependem do atendimento di√°rio.

Entrevistador: Por √∫ltimo, pode descrever mais detalhes sobre sua manifesta√ß√£o?
Pessoa: Claro, a manifesta√ß√£o √© sobre car√™ncia de profissionais de sa√∫de que afeta o atendimento aos cidad√£os locais.

Entrevistador: Muito obrigado pelas informa√ß√µes, Maria Costa! Vamos processar sua manifesta√ß√£o e entrar em contato em breve.
```

### JSON Output

```json
{
    "id": "78bd0fea-5c5f-4a7c-97ca-9be3803fe21d",
    "conversation": "Entrevistador: Ol√°, como posso ajud√°-lo hoje? Vamos come√ßar com algumas perguntas b√°sicas. Qual √© o seu nome?\nPessoa: Meu nome √© Maria Costa.\n\nEntrevistador: √ìtimo, Maria Costa! Qual √© o seu email?\nPessoa: Meu email √© maria.costa@email.com.\n\nEntrevistador: Perfeito! E qual √© o n√∫mero do seu telefone celular?\nPessoa: Meu n√∫mero de telefone celular √© (41) 66666-5555.\n\nEntrevistador: Agora, precisamos de algumas informa√ß√µes espec√≠ficas sobre a manifesta√ß√£o. Qual √© o √≥rg√£o relacionado com a manifesta√ß√£o?\nPessoa: O √≥rg√£o relacionado √© Departamento de Tr√¢nsito.\n\nEntrevistador: Entendido. E qual √© o local relacionado √† sua manifesta√ß√£o?\nPessoa: O local √© Rua XV de Novembro, n√∫mero 300, S√£o Paulo.\n\nEntrevistador: Certo. Qual √© o servi√ßo para o qual deve ser lan√ßada a manifesta√ß√£o?\nPessoa: O servi√ßo √© manuten√ß√£o de sem√°foros.\n\nEntrevistador: √ìtimo. Sobre o que voc√™ gostaria de falar?\nPessoa: Eu gostaria de falar sobre demora na manuten√ß√£o dos sem√°foros que est√° causando muitos congestionamentos.\n\nEntrevistador: Entendi. Quem s√£o os envolvidos na sua manifesta√ß√£o?\nPessoa: Os envolvidos s√£o moradores da regi√£o e os motoristas.\n\nEntrevistador: Por √∫ltimo, pode descrever mais detalhes sobre sua manifesta√ß√£o?\nPessoa: Claro, a manifesta√ß√£o √© sobre urg√™ncia na manuten√ß√£o dos sem√°foros na Avenida Paulista, causada por congestionamentos e acidentes.\n\nEntrevistador: Muito obrigado pelas informa√ß√µes, Maria Costa! Vamos processar sua manifesta√ß√£o e entrar em contato em breve.\n\n",
    "json_response": {
        "name": "Maria Costa",
        "email": "maria.costa@email.com",
        "phone_number": "(41) 66666-5555",
        "department": "Departamento de Tr√¢nsito",
        "issue": "Manifesta√ß√£o sobre urg√™ncia na manuten√ß√£o de sem√°foros na Avenida Paulista",
        "service": "Manuten√ß√£o de sem√°foros",
        "additional_information": "Manuten√ß√£o de sem√°foros na Avenida Paulista, causada por congestionamentos e acidentes, com a urg√™ncia de manuten√ß√£o.",
        "sentiment_analysis": {
            "text": "\nThe sentiment of the text is \"Positive\". The text discusses a public event and the importance of maintaining the infrastructure of the event. The text also mentions the importance of ensuring the safety of attendees and the need for efficient communication."
        }
    }
}
```

## Setup and Configuration

- Kafka server and topic configuration are required for message consumption and production.
- The HuggingFace inference server URL must be set for LLM operations.
- Logging is configured for monitoring and debugging purposes.

## Environment Setup üåç

To set up your environment to run the code, first install all requirements:

1. üì• Clone the repo using git:

```shell
git clone https://github.com/gsampaio-rh/hftgi-apps
```

2. Create and Activate a Virtual Environment:

```bash
  python -m venv .env
  source .env/bin/activate
```

3. üõ†Ô∏è Install the dependencies using pip

```shell
pip install -r requirements.txt
```

### Inference Server Setup

The inference server is responsible for performing text inference tasks using Hugging Face's Large Language Models. You need to specify the URL of the inference server that the application will communicate with.

- `inference_server_url` should be set to the URL of your Hugging Face inference server. If you're running the server locally for testing, you can use "http://localhost:3000/". For production or cloud environments, you would replace this with the actual URL of your deployed inference server.

### Kafka Setup

This application uses Kafka for message queueing, consuming messages from a chat topic, processing them, and then producing responses to an answer topic.

- `kafka_server` specifies the address of your Kafka server. If running locally, it's typically set to "localhost:9092". For production, this would be the address of your Kafka cluster.
- `consumer_topic` is the name of the Kafka topic from which the application will consume messages. This should be set to "chat" or whichever topic you have designated for incoming chat messages.
- `producer_topic` is the name of the Kafka topic to which the application will produce processed messages. This is set to "answer", or any other topic name where you want the processed messages to be published.

Ensure these settings are correctly configured to match your environment before running the application.

## Running the Application üöÄ

To run the application, follow these steps:

1. **Run the Application**:

```bash
python app.py
```

## Contribution

Contributions to the `hftgi-apps` project are welcome. Whether you're fixing a bug, proposing a new feature, or improving the documentation, your support helps improve the project for everyone.

## License

The `hftgi-apps` project is open-sourced under a specified license, allowing for modification, personal use, and distribution within the terms of that license. Please review the license details for more information on your rights and restrictions.